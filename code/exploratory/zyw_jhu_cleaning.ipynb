{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally by Tom Roeschinger (2020)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "from io import StringIO\n",
    "import os\n",
    "import us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, val_name=\"Cases\"):\n",
    "    \"\"\"Cleans up dataframe\"\"\"\n",
    "    \n",
    "    # convert to longform\n",
    "    df = df.melt(value_vars=df.columns[4:],id_vars=df.columns[0:4], var_name=\"Date\", value_name=val_name)\n",
    "    \n",
    "    # clean datatypes\n",
    "    df['Province/State'] = df['Province/State'].astype('string')\n",
    "    df['Country/Region'] = df['Country/Region'].astype('string')\n",
    "    df['Date'] = df['Date'].astype('datetime64')\n",
    "    return df\n",
    "\n",
    "def tidy_provinces(df):\n",
    "    \"\"\"Split complex state/province names (US only so far)\"\"\"\n",
    "    # Clean so DC appears as a single 'state'\n",
    "    df.loc[df['Province/State'].str.contains('Washington, D.C.'),\n",
    "           'Province/State'] = 'Washington DC'\n",
    "    df['City/County'] = pd.Series(np.repeat(pd.NA, len(df)), dtype='string')\n",
    "    \n",
    "    # Select Province/State combinations with a comma\n",
    "    comma_filter = df['Province/State'].str.contains(',')\n",
    "    # Extract city or county name\n",
    "    cities_counties = (df[comma_filter]['Province/State']\n",
    "                       .apply(lambda string: string.split(',')[0].strip())\n",
    "                       .astype('string'))\n",
    "    # Extract state abbreviation and fix as fullname\n",
    "    states = (df[comma_filter]['Province/State']\n",
    "              .apply(lambda string: string.split(',')[1].strip())\n",
    "              .apply(lambda state: us.states.lookup(state).name)\n",
    "              .astype('string'))\n",
    "    # Assign into data frame\n",
    "    df.loc[comma_filter, 'City/County'] = cities_counties\n",
    "    df.loc[comma_filter, 'Province/State'] = states\n",
    "    \n",
    "    return df[['City/County'] +  df.columns[df.columns != 'City/County'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209          Kitsap\n",
      "210          Solano\n",
      "211      Santa Cruz\n",
      "212            Napa\n",
      "213         Ventura\n",
      "            ...    \n",
      "29615       Socorro\n",
      "29616    Bernalillo\n",
      "29617       Oakland\n",
      "29618         Wayne\n",
      "29619    New Castle\n",
      "Name: Province/State, Length: 11590, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# urls for data in Johns Hopkins github repository\n",
    "urls = {'Confirmed' : \"https://raw.github.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\",\n",
    "        'Deaths' : \"https://raw.github.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\",\n",
    "        'Recovered' : \"https://raw.github.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\"}\n",
    "\n",
    "output_dfs = {}\n",
    "\n",
    "for condition, url in urls.items():\n",
    "    request = requests.get(url)\n",
    "    txt = StringIO(req.text)\n",
    "    df = pd.read_csv(txt)\n",
    "    output_dfs[condition] = clean_df(df,val_name=condition)\n",
    "    \n",
    "df = (output_dfs['Confirmed']\n",
    "      .merge(output_dfs['Deaths'])\n",
    "      .merge(output_dfs['Recovered']))\n",
    "\n",
    "df = tidy_provinces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City/County</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>47.4009</td>\n",
       "      <td>-121.4905</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>42.1657</td>\n",
       "      <td>-74.9481</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>36.1162</td>\n",
       "      <td>-119.6816</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>42.2302</td>\n",
       "      <td>-71.5301</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Diamond Princess</td>\n",
       "      <td>US</td>\n",
       "      <td>35.4437</td>\n",
       "      <td>139.6380</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29619</th>\n",
       "      <td>New Castle</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>US</td>\n",
       "      <td>39.5393</td>\n",
       "      <td>-75.6674</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29634</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29637</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>18.2208</td>\n",
       "      <td>-66.5901</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>13.4443</td>\n",
       "      <td>144.7937</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29668</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.3358</td>\n",
       "      <td>-64.8963</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15067 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      City/County    Province/State Country/Region      Lat      Long  \\\n",
       "98           <NA>        Washington             US  47.4009 -121.4905   \n",
       "99           <NA>          New York             US  42.1657  -74.9481   \n",
       "100          <NA>        California             US  36.1162 -119.6816   \n",
       "101          <NA>     Massachusetts             US  42.2302  -71.5301   \n",
       "102          <NA>  Diamond Princess             US  35.4437  139.6380   \n",
       "...           ...               ...            ...      ...       ...   \n",
       "29619  New Castle          Delaware             US  39.5393  -75.6674   \n",
       "29634        <NA>           Alabama             US  32.3182  -86.9023   \n",
       "29637        <NA>       Puerto Rico             US  18.2208  -66.5901   \n",
       "29651        <NA>              Guam             US  13.4443  144.7937   \n",
       "29668        <NA>    Virgin Islands             US  18.3358  -64.8963   \n",
       "\n",
       "            Date  Confirmed  Deaths  Recovered  \n",
       "98    2020-01-22          0       0          0  \n",
       "99    2020-01-22          0       0          0  \n",
       "100   2020-01-22          0       0          0  \n",
       "101   2020-01-22          0       0          0  \n",
       "102   2020-01-22          0       0          0  \n",
       "...          ...        ...     ...        ...  \n",
       "29619 2020-03-22          0       0          0  \n",
       "29634 2020-03-22          0       0          0  \n",
       "29637 2020-03-22          0       0          0  \n",
       "29651 2020-03-22          0       0          0  \n",
       "29668 2020-03-22          0       0          0  \n",
       "\n",
       "[15067 rows x 9 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country/Region']=='US']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:covidmodels]",
   "language": "python",
   "name": "conda-env-covidmodels-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
